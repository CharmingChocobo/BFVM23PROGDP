{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before working on this assignment please read the instructions fully. Use blackboard to submit a link to your repository. Upload a rendered document (html/pdf) as well as the original code. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "You should define a research question yourself based on at least two data sources that can be merged into a tidy dataset. The research question should be life science related. The research question should be a question with a causual nature. For instance questions like: How do independent variables X influence the dependent variable of Y? The research question should be answered with an interactive visual, and if possible tested for significance.\n",
    "If you use code snippets from others you should refer to the original author, otherwise you will be accused of plagiarism. Please be prepared to explain your code in a verbal exam. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessment criteria:\n",
    "\n",
    "Conditional\n",
    "- No data and or api-key information is stored in the repository.\n",
    "- No hard datapaths are used, datapaths are provided in a configfile.\n",
    "- At least two data sets are merged into one tidy dataframe.\n",
    "\n",
    "Graded\n",
    "- **Research Question (5 pt)**: The research question is clearly stated. The research questions support the exploration of the research objectives within the introduction. It drives the data acquisition and analysis processes.\n",
    "- **Data Sources and Metadata (5 pt)**: Links to sources and clear instructions on how to access the data is provided. Additionally, metadata descriptions to offer insights into the nature and structure of the data is provided.\n",
    "- **Data Quality and Quantity (20 pt)**: An exhaustive evaluation of data quality, encompassing accuracy, completeness, and consistency, is undertaken, ensuring suitability for analysis purposes. Python code in combination with Pandas and Numpy libraries serves as the primary tool for executing essential preprocessing steps and transformations aimed at enhancing data quality.\n",
    "- **Conduct Critical Research (20 pt)**: Assumptions are clearly stated and all design choices such as data storage format, analysis methods, and vidualization design are justified. An argumentative approach is used to explain steps taken, considering data quality and quantity. This explanation is documented within the code or in a separate document. The student critically questions and engages with all pertinent elements, drawing conclusions grounded in a holistic understanding of the subject matter.\n",
    "- **Interactive Visualization (10 pt)**: The interactive visualizations are accompanied by self-explanatory captions, accurately labeled axes with units and legends, exhibit visual appeal, and are founded on appropriately preprocessed data.\n",
    "- **Design Alignment and Functionality (10 pt)**: The project design supports the research question and data is informative regarding the topic. The presented results are highly informative in relation to the research topic. Both the quantity and quality of the tables and visualizations are sufficient, collectively offering robust evidence to underpin the research conclusions.\n",
    "- **Efficient and Error-free Code (20 pt)**: Code follows coding standards, is efficient, readable, and free of errors. The code aims for maintainability and flexibility, allowing for future modifications without compromising functionality.\n",
    "- **Repository and Documentation (10 pt)**: All code is stored in a repository and include a comprehensive README file. The README should contain relevant implementation information, software licenses, and documentation for easy understanding and implementation by others. The code is a well-organized and well-documented codebase, with clear separation of concerns and modular components \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data\n",
    "\n",
    "You can either choose \n",
    "- a dataset combination provided on blackboard\n",
    "- two datasets on the web from two different sources which can be used to answer a research question\n",
    "- the data from your project\n",
    "\n",
    "You are welcome to choose datasets at your discretion, but keep in mind they will be shared with others, so choose appropriate datasets. You are welcome to use datasets of your own as well, but minimual two datasets should be coming from the web and or API's. \n",
    "\n",
    "Also, you are welcome to preserve data in its original language, but for the purposes of grading you should provide english translations in your visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "Define a research question, select data and code your data acquisition, data processing, data analysis and interactive visualization. Use a repository with a commit strategy and write a readme file. Make sure that you document your choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
